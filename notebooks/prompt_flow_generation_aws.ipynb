{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Bedrock Prompt Flow Generation \n",
    "\n",
    "This notebook shows how we can take the Amazon Bedrock Knowledge Bases we created in `rag-router.ipynb` and put them in a structured flow using Amazon Bedrock Prompt Flows (https://aws.amazon.com/bedrock/prompt-flows/).\n",
    "\n",
    "This will allow us to have a versioned flow where we can specify all of the sequential components, as well as any conditions we want to model. \n",
    "\n",
    "We create promtps we will store in \n",
    "\n",
    "We will start with a description of a RAG framework with additional modules (e.g., current date, web search, etc.) to generate a prompt flow as shown below.\n",
    "\n",
    "** Generated Prompt Flow**\n",
    "\n",
    "![alt text](prompt_flow_asset/example_pf_output.png \"Automatically Generated Prompt Flow\")\n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents:**\n",
    "\n",
    "1. [Complete prerequisites](#Complete%20prerequisites)\n",
    "    \n",
    "    1. [Configure logging](#Configure%20logging)\n",
    "        \n",
    "        1. [System logs (Optional)](#Configure%20system%20logs%20(Optional))\n",
    "        \n",
    "        2. [Application logs](#Configure%20application%20logs)\n",
    "    \n",
    "    2. [Organize imports](#Organize%20imports)\n",
    "    \n",
    "    3. [Set AWS Region and boto3 config](#Set%20AWS%20Region%20and%20boto3%20config)\n",
    "    \n",
    "    4. [Create common objects](#Create%20common%20objects)\n",
    "    \n",
    "    5. [Get details of Knowledge Bases](#Get%20details%20of%20Knowledge%20Bases)\n",
    "\n",
    " 2. [Create Prompts](#Load%20data%20to%20Knowledge%20Bases)\n",
    "    \n",
    "    1. [Step 0a: Create prompt for routing](#Load%20to%20KB%20Step0b)\n",
    "    \n",
    "    2. [Step 0b: Create prompt for AI Assistant](#Load%20to%20KB%20Steps0c%20to%200e)\n",
    " \n",
    " 3. [Create Flow](#Process%20query)\n",
    " \n",
    "     1. [Step 1: User query and non-KB query](#User%20query)\n",
    "     \n",
    "     2. [Steps 2a and 2b: Determine the KB id](#Determine%20the%20KB%20id)\n",
    "     \n",
    "     3. [Steps 3a through 5: Retrieve and generate](#Retrieve%20and%20generate)\n",
    " \n",
    " 4. [Cleanup](#Cleanup)\n",
    " \n",
    " 5. [Conclusion](#Conclusion)\n",
    " \n",
    " 6. [Frequently Asked Questions (FAQs)](#FAQs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  b. Application logs <a id='Configure%20application%20logs'></a>\n",
    "\n",
    "Application logs refers to the logs generated by running the various code cells in this notebook. To set this up, instantiate the [Python logging service](https://docs.python.org/3/library/logging.html) by running the following cell. You can configure the default log level and format as required.\n",
    "\n",
    "By default, this notebook will only print the logs to the corresponding cell's output console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# Set the logging level and format\n",
    "log_level = logging.INFO\n",
    "log_format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(level=log_level, format=log_format)\n",
    "\n",
    "# Save these in the environment variables for use in the helper scripts\n",
    "os.environ['LOG_LEVEL'] = str(log_level)\n",
    "os.environ['LOG_FORMAT'] = log_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  B. Organize imports <a id ='Organize%20imports'> </a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "# Import the helper functions from the 'scripts' folder\n",
    "sys.path.append(os.path.join(os.getcwd(), \"scripts\"))\n",
    "#logging.info(\"Updated sys.path: {}\".format(sys.path))\n",
    "from helper_functions import *\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bedrock_agent = boto3.client(service_name=\"bedrock-agent\", region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  C. Get KB Details <a id ='Organize%20imports'> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_1_name = 'rag-router-kb-1'\n",
    "kb_2_name = 'rag-router-kb-2'\n",
    "\n",
    "\n",
    "kb_1_id, kb_1_ds_id, kb_1_s3_bucket_name, kb_1_aoss_collection_arn = get_kb_details(bedrock_agent, kb_1_name)\n",
    "kb_2_id, kb_2_ds_id, kb_2_s3_bucket_name, kb_2_aoss_collection_arn = get_kb_details(bedrock_agent, kb_2_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Create Prompts <a id =Load%20data%20to%20Knowledge%20Bases> </a>\n",
    "\n",
    "Let's create a prompt for our AI Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt\n",
    "response = bedrock_agent.create_prompt(\n",
    "    name=f\"AIAssistantPrompt-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    description=\"AI Assistant prompt for Amazon Bedrock Knowledge Base\",\n",
    "    variants=[\n",
    "        {\n",
    "            \"inferenceConfiguration\": {\n",
    "                \"text\": {\n",
    "                    \"maxTokens\": 3000,\n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.1,\n",
    "                    # \"topK\": 250,\n",
    "                }\n",
    "            },\n",
    "            \"modelId\": \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "            \"name\": \"variant-001\",\n",
    "            \"templateConfiguration\": {\n",
    "                \"text\": {\n",
    "                    \"inputVariables\": [\n",
    "                        {\"name\": \"user_query\"},\n",
    "                        {\"name\": \"kb_results\"}\n",
    "                    ],\n",
    "                    \"text\": \"\"\"You are an AI assistant who is well-versed in Amazon Bedrock Knowledge base designed to answer a user's question.\n",
    "Please generate a code about Amazon Bedrock Knowledge Base only when a user asks for it.\n",
    "Do NOT use your own knowledge as facts in answers. \n",
    "Please output a list in order of the most valuable data sources for a knowledge base when appropriate.\n",
    "Don't restate the instructions.\n",
    "\n",
    "User query: {{user_query}}\n",
    "\n",
    "Knowledge base results: {{kb_results}}\n",
    "\n",
    "Please provide a response based on the above information:\"\"\"\n",
    "                }\n",
    "            },\n",
    "            \"templateType\": \"TEXT\"\n",
    "        }\n",
    "    ],\n",
    "    defaultVariant=\"variant-001\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  E. Create Prompts <a id =Load%20data%20to%20Knowledge%20Bases> </a>\n",
    "\n",
    "Let's create a prompt for our AI Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_response = bedrock_agent.create_prompt(\n",
    "    name=f\"AIRouterPrompt-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    description=\"AI Router prompt for Amazon Bedrock Knowledge Base\",\n",
    "    variants=[\n",
    "        {\n",
    "            \"inferenceConfiguration\": {\n",
    "                \"text\": {\n",
    "                    \"maxTokens\": 500,\n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.1,\n",
    "                    # \"topK\": 250,\n",
    "                }\n",
    "            },\n",
    "            \"modelId\": \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "            \"name\": \"variant-001\",\n",
    "            \"templateConfiguration\": {\n",
    "                \"text\": {\n",
    "                    \"inputVariables\": [\n",
    "                        {\"name\": \"QUERY\"}\n",
    "                    ],\n",
    "                    \"text\": \"\"\"Carefully take a look at the CATEGORY information specified in the <KBs> tag.\n",
    "<KBs>\n",
    "<CATEGORY1>code</CATEGORY2>\n",
    "<CATEGORY1>docs</CATEGORY2>\n",
    "</KBs>\n",
    "\n",
    "Look at the query specified in the <QUERY> tag.\n",
    "\n",
    "<QUERY>\n",
    "{{QUERY}}\n",
    "</QUERY>\n",
    "\n",
    "Now, look at the output JSON format specified in the <OUTPUT> tag.\n",
    "\n",
    "<OUTPUT>\n",
    "{\n",
    "  \"category\": \"\",\n",
    "}\n",
    "</OUTPUT>\n",
    "\n",
    "Now, follow the instructions specified in the <INSTRUCTIONS> tag.\n",
    "<INSTRUCTIONS>\n",
    "- Identify the category for the query specified in the <QUERY> tag. It should be one of the values specified in the <CATEGORY> tags inside the <KBs> tag.\n",
    "- Based on the identified category, create an output JSON message as specified in the <OUTPUT> tag with corresponding values for \"category\".\n",
    "- If you do not know the answer, mention the \"category\" as \"UNKNOWN\".\n",
    "- Your response should ONLY be a valid JSON as specified in the <OUTPUT> tag.\n",
    "- Do not make up an answer.\n",
    "- Do not include any preamble or postamble.\n",
    "</INSTRUCTIONS>\"\"\"\n",
    "                }\n",
    "            },\n",
    "            \"templateType\": \"TEXT\"\n",
    "        }\n",
    "    ],\n",
    "    defaultVariant=\"variant-001\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_prompt_arn = assistant_response[\"arn\"]\n",
    "print(f\"Assistant Prompt ARN: {assistant_prompt_arn}\")\n",
    "router_prompt_arn = router_response[\"arn\"]\n",
    "print(f\"Router Prompt ARN: {router_prompt_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "After updating the generated code with your inputs on the required configurations, you can simple execute the generated code that is saved as a python file.\n",
    "\n",
    "Please review the generated code before you execute it and see if everything is correct. \n",
    "\n",
    "If there was an error(s) in the code, the execution module will tell you what went wrong with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_arn = response[\"arn\"]\n",
    "print(f\"Prompt ARN: {prompt_arn}\")\n",
    "\n",
    "# Create the flow\n",
    "flow_role = role #\"arn:aws:iam::123456789012:role/BedrockFlowRole\"  # Replace with your actual role ARN\n",
    "kb_id = \"\" # Replace with your actual knowledge base ID\n",
    "\n",
    "response = bedrock_agent.create_flow(\n",
    "    name=f\"BedrockKnowledgeBaseFlow-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    description=\"Flow for answering questions about Amazon Bedrock Knowledge Base\",\n",
    "    executionRoleArn=flow_role,\n",
    "    definition={\n",
    "        \"nodes\": [\n",
    "            {\n",
    "                \"name\": \"UserInput\",\n",
    "                \"type\": \"Input\",\n",
    "                \"configuration\": {\n",
    "                    \"input\": {}\n",
    "                },\n",
    "                \"outputs\": [\n",
    "                    {\n",
    "                        \"name\": \"document\",\n",
    "                        \"type\": \"String\"\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"BedrockKnowledgeBase\",\n",
    "                \"type\": \"KnowledgeBase\",\n",
    "                \"configuration\": {\n",
    "                    \"knowledgeBase\": {\n",
    "                        \"knowledgeBaseId\": kb_1_id  \n",
    "                    }\n",
    "                },\n",
    "                \"inputs\": [\n",
    "                    {\n",
    "                        \"name\": \"retrievalQuery\",\n",
    "                        \"type\": \"String\",\n",
    "                        \"expression\": \"$.data\"\n",
    "                    }\n",
    "                ],\n",
    "                \"outputs\": [\n",
    "                    {\n",
    "                        \"name\": \"retrievalResults\",\n",
    "                        \"type\": \"Array\"\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"AIAssistant\",\n",
    "                \"type\": \"Prompt\",\n",
    "                \"configuration\": {\n",
    "                    \"prompt\": {\n",
    "                        \"sourceConfiguration\": {\n",
    "                            \"resource\": {\n",
    "                                \"promptArn\": assistant_prompt_arn\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"inputs\": [\n",
    "                    {\n",
    "                        \"name\": \"user_query\",\n",
    "                        \"type\": \"String\",\n",
    "                        \"expression\": \"$.data\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"kb_results\",\n",
    "                        \"type\": \"Array\",\n",
    "                        \"expression\": \"$.data\"\n",
    "                    }\n",
    "                ],\n",
    "                \"outputs\": [\n",
    "                    {\n",
    "                        \"name\": \"modelCompletion\",\n",
    "                        \"type\": \"String\"\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"FinalResponse\",\n",
    "                \"type\": \"Output\",\n",
    "                \"configuration\": {\n",
    "                    \"output\": {}\n",
    "                },\n",
    "                \"inputs\": [\n",
    "                    {\n",
    "                        \"name\": \"document\",\n",
    "                        \"type\": \"String\",\n",
    "                        \"expression\": \"$.data\"\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        \"connections\": [\n",
    "            {\n",
    "                \"name\": \"Connection_1\",\n",
    "                \"source\": \"UserInput\",\n",
    "                \"target\": \"BedrockKnowledgeBase\",\n",
    "                \"type\": \"Data\",\n",
    "                \"configuration\": {\n",
    "                    \"data\": {\n",
    "                        \"sourceOutput\": \"document\",\n",
    "                        \"targetInput\": \"retrievalQuery\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Connection_2\",\n",
    "                \"source\": \"UserInput\",\n",
    "                \"target\": \"AIAssistant\",\n",
    "                \"type\": \"Data\",\n",
    "                \"configuration\": {\n",
    "                    \"data\": {\n",
    "                        \"sourceOutput\": \"document\",\n",
    "                        \"targetInput\": \"user_query\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Connection_3\",\n",
    "                \"source\": \"BedrockKnowledgeBase\",\n",
    "                \"target\": \"AIAssistant\",\n",
    "                \"type\": \"Data\",\n",
    "                \"configuration\": {\n",
    "                    \"data\": {\n",
    "                        \"sourceOutput\": \"retrievalResults\",\n",
    "                        \"targetInput\": \"kb_results\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Connection_4\",\n",
    "                \"source\": \"AIAssistant\",\n",
    "                \"target\": \"FinalResponse\",\n",
    "                \"type\": \"Data\",\n",
    "                \"configuration\": {\n",
    "                    \"data\": {\n",
    "                        \"sourceOutput\": \"modelCompletion\",\n",
    "                        \"targetInput\": \"document\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "flow_id = response[\"id\"]\n",
    "flow_arn = response[\"arn\"]\n",
    "flow_name = response[\"name\"]\n",
    "print(f\"Flow ID: {flow_id}\")\n",
    "print(f\"Flow ARN: {flow_arn}\")\n",
    "print(f\"Flow Name: {flow_name}\")\n",
    "\n",
    "# Prepare the flow\n",
    "response = bedrock_agent.prepare_flow(flowIdentifier=flow_id)\n",
    "print(json.dumps(response, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_response = bedrock_agent.create_flow_version(\n",
    "    # clientToken='string',\n",
    "    description='main-flow-version',\n",
    "    flowIdentifier=flow_id\n",
    ")\n",
    "version_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_response = bedrock_agent.create_flow_alias(\n",
    "    # clientToken='string',\n",
    "    description='Main flow Alias',\n",
    "    flowIdentifier=flow_id,\n",
    "    name=\"main-flow-alias\",\n",
    "    routingConfiguration=[\n",
    "        {\n",
    "            'flowVersion': '1'\n",
    "        },\n",
    "    ],\n",
    "    # tags={\n",
    "    #     'string': 'string'\n",
    "    # }\n",
    ")\n",
    "alias_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agent_rt = boto3.client(service_name=\"bedrock-agent-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "query = \"tell me about KBs\"\n",
    "\n",
    "response = bedrock_agent_rt.invoke_flow(\n",
    "    flowAliasIdentifier='0D8SVYHPBT',\n",
    "    flowIdentifier=flow_id,\n",
    "    inputs=[\n",
    "        {\n",
    "            'content': {\n",
    "                'document': query\n",
    "            },\n",
    "            'nodeName': 'UserInput',\n",
    "            'nodeOutputName': 'document'\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "[response for response in iter(response['responseStream'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the generated Prompt Flow \n",
    "\n",
    "After successfully executing the prompt flow deployment code, your prompt flow is deployed to your AWS account. \n",
    "\n",
    "Please go to your AWS console and go to Amazon Bedrock.\n",
    "\n",
    "In the left panel, go to Prompt flows (preview) under Builder's tool.\n",
    "\n",
    "Your prompt flow will be in the prompt flows list in the main panel. \n",
    "\n",
    "![alt text](prompt_flow_asset/example_pf_list.png \"Prompt Flows List\")\n",
    "\n",
    "\n",
    "Click the generate prompt flow and Click Edit in prompt flow builder button in the top right corner.\n",
    "\n",
    "![alt text](prompt_flow_asset/example_pf_panel.png \"Prompt Flow Panel\")\n",
    "\n",
    "You will be able to see the draft of the generated prompt flow and test it with your questions about Amazon Bedrock Knowledge Base.\n",
    "\n",
    "![alt text](prompt_flow_asset/example_pf_output.png \"Automatically Generated Prompt Flow\")\n",
    "\n",
    "Thank you for following this example all the way to the end. Have fun building!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
