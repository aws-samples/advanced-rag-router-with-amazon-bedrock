{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our flow\n",
    "\n",
    "The prior notebook showed us how we can take the Amazon Bedrock Knowledge Bases we created in `setup_knowledge_bases.ipynb` and put them in a structured flow using Amazon Bedrock Prompt Flows (https://aws.amazon.com/bedrock/prompt-flows/).\n",
    "\n",
    "This notebook wil demonstrate how we can evaluate the accuracy of our flows using the [Ragas](https://docs.ragas.io/en/stable/getstarted/) framework. This is a commonly used open source framework for evaluating RAG application accuracy.\n",
    "\n",
    "Let's start with some imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents:**\n",
    "\n",
    "1. [Complete prerequisites](#Complete%20prerequisites)\n",
    "                \n",
    "    b. [Organize imports](#Organize%20imports)\n",
    "    \n",
    "    c. [Set AWS Region and boto3 config](#Set%20AWS%20Region%20and%20boto3%20config)\n",
    "    \n",
    "    d. [Get our flows](#Create%20common%20objects)\n",
    "    \n",
    " 2. [Load Dataset](#Load%20data%20to%20Knowledge%20Bases)\n",
    " \n",
    " 3. [Execute Flows](#Cleanup)\n",
    "\n",
    " 4. [Measure Accuracy](#Cleanup)\n",
    " \n",
    " 5. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1a. Organize Imports <a id =Load%20data%20to%20Knowledge%20Bases> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from botocore.client import Config\n",
    "from langchain_aws.chat_models.bedrock import ChatBedrock\n",
    "from langchain_aws.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_aws.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    "    answer_relevancy,\n",
    "    faithfulness\n",
    "    )\n",
    "\n",
    "model_id_eval = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent = boto3.client(service_name=\"bedrock-agent\", region_name=\"us-west-2\")\n",
    "bedrock_agent_rt = boto3.client(service_name=\"bedrock-agent-runtime\", region_name=\"us-west-2\")\n",
    "llm_for_evaluation = ChatBedrock(model_id= model_id_eval, client=bedrock_client)\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\",\n",
    "                                                    client=bedrock_client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1b. Get our flows <a id =Load%20data%20to%20Knowledge%20Bases> </a>\n",
    "\n",
    "Let's collect our flow ids and our flow aliases, this will allow us to call the flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_summaries = bedrock_agent.list_flows()['flowSummaries']\n",
    "flow_id = flow_summaries[0]['id']\n",
    "\n",
    "flow_aliases = bedrock_agent.list_flow_aliases(flowIdentifier = flow_id)['flowAliasSummaries']\n",
    "flow_alias = flow_aliases[0]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Load our dataset <a id =Load%20data%20to%20Knowledge%20Bases> </a>\n",
    "\n",
    "\n",
    "Let's load our question and answer pairs we can use for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_set = pd.read_csv(\"data/questions_and_answers.csv\")\n",
    "question_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3. Execute our flow <a id =Load%20data%20to%20Knowledge%20Bases> </a>\n",
    "\n",
    "The below will invoke our flow and store the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_outputs = []\n",
    "for question in tqdm(question_set['question']):\n",
    "\n",
    "    response = bedrock_agent_rt.invoke_flow(\n",
    "        flowAliasIdentifier=flow_alias,\n",
    "        flowIdentifier=flow_id,\n",
    "        inputs=[\n",
    "            {\n",
    "                'content': {\n",
    "                    'document': question\n",
    "                },\n",
    "                'nodeName': 'FlowInputNode',\n",
    "                'nodeOutputName': 'document'\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    flow_output = [response for response in iter(response['responseStream'])]\n",
    "\n",
    "    flow_outputs.append(flow_output[0]['flowOutputEvent']['content']['document'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Measure Accuracy <a id =Load%20data%20to%20Knowledge%20Bases> </a>\n",
    "\n",
    "Now that we have our prompt flow responses, we can evaluate them using the Ragas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = []\n",
    "for context in tqdm(question_set['llm_contexts']):\n",
    "    eval(context)\n",
    "    context_list.append(eval(context))\n",
    "\n",
    "metrics = [\n",
    "          # context_precision,\n",
    "        # context_recall, # currently this metric might trigger timeout error raised by bedrock: ValueError: Error raised by bedrock service: Read timeout on endpoint URL: \"https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-v2/invoke\"\n",
    "        answer_similarity,\n",
    "        answer_correctness,\n",
    "        # answer_relevancy,\n",
    "        # faithfulness\n",
    "]\n",
    "\n",
    "column_map = {\n",
    "        \"question\": \"question\",\n",
    "        \"contexts\": \"llm_contexts\",\n",
    "        \"answer\": \"llm_answer\",\n",
    "        \"reference\": \"reference\",\n",
    "    }\n",
    "\n",
    "ragas_dataset = Dataset.from_dict(    {\n",
    "        \"question\":question_set['question'],\n",
    "        \"llm_answer\":flow_outputs,\n",
    "        \"reference\":question_set['gt_answer'],\n",
    "        \"llm_contexts\":context_list\n",
    "    })\n",
    "\n",
    "# Evaluate\n",
    "eval_result = evaluate(ragas_dataset, \n",
    "                       metrics=metrics, \n",
    "                       column_map=column_map, \n",
    "                       llm=llm_for_evaluation,\n",
    "                        embeddings=bedrock_embeddings, raise_exceptions=False)\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleanup <a id='Cleanup'></a>\n",
    "\n",
    "As a best practice, you should delete AWS resources that are no longer required.  This will help you avoid incurring unncessary costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> If you are running this notebook as part of a workshop session, by default, all resources will be cleaned up at the end of the session. If you are running this notebook outside of a workshop session, you can cleanup the resources associated with this notebook by uncommenting the following code cell and running it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following cell will delete the following resources:\n",
    "* Knowledge Bases.\n",
    "* Amazon OpenSearch Serverless Collections.\n",
    "* The files that were uploaded to the S3 buckets; not the S3 buckets themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Note: 'delete_kb' available through ./scripts/helper_functions.py\n",
    "delete_kb(bedrock_agt_client, kb_1_id)\n",
    "delete_kb(bedrock_agt_client, kb_2_id)\n",
    "\n",
    "# Note: 'delete_aoss_collection' and 'get_aoss_collection_id' are available through ./scripts/helper_functions.py\n",
    "delete_aoss_collection(aoss_client, get_aoss_collection_id(kb_1_aoss_collection_arn))\n",
    "delete_aoss_collection(aoss_client, get_aoss_collection_id(kb_2_aoss_collection_arn))\n",
    "\n",
    "# Note: 'delete_s3_object' available through ./scripts/helper_functions.py\n",
    "delete_s3_object(s3_client, kb_1_s3_bucket_name, s3_key_prefix + '/' + kb_1_downloaded_file_name)\n",
    "delete_s3_object(s3_client, kb_2_s3_bucket_name, s3_key_prefix + '/' + kb_2_downloaded_file_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion <a id='Conclusion'></a>\n",
    "\n",
    "We have now seen how to build an advanced RAG router based assistant with Amazon Bedrock using Amazon Bedrock Prompt Flows. In the process, we learned how Amazon Bedrock with its LLMs, and Knowledge Bases (KBs) make it easy for you to build generative AI applications."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
