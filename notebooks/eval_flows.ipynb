{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our flow\n",
    "\n",
    "This notebook shows how we can take the Amazon Bedrock Knowledge Bases we created in `rag-router.ipynb` and put them in a structured flow using Amazon Bedrock Prompt Flows (https://aws.amazon.com/bedrock/prompt-flows/).\n",
    "\n",
    "This will allow us to have a versioned flow where we can specify all of the sequential components, as well as any conditions we want to model. \n",
    "\n",
    "We will start with a description of a RAG framework with additional modules (e.g., current date, web search, etc.) to generate a prompt flow as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from botocore.client import Config\n",
    "from langchain_aws.chat_models.bedrock import ChatBedrock\n",
    "from langchain_aws.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_aws.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    "    answer_relevancy,\n",
    "    faithfulness\n",
    "    )\n",
    "\n",
    "model_id_eval = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent = boto3.client(service_name=\"bedrock-agent\", region_name=\"us-west-2\")\n",
    "bedrock_agent_rt = boto3.client(service_name=\"bedrock-agent-runtime\", region_name=\"us-west-2\")\n",
    "llm_for_evaluation = ChatBedrock(model_id= model_id_eval, client=bedrock_client)\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",\n",
    "                                                    client=bedrock_client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get our flows\n",
    "\n",
    "Let's collect our flow ids and our flow aliases, this will allow us to call the flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_summaries = bedrock_agent.list_flows()['flowSummaries']\n",
    "flow_id = flow_summaries[0]['id']\n",
    "\n",
    "flow_aliases = bedrock_agent.list_flow_aliases(flowIdentifier = flow_id)['flowAliasSummaries']\n",
    "flow_alias = flow_aliases[0]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our dataset\n",
    "\n",
    "Let's load our question and answer pairs we can use for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_set = pd.read_csv(\"data/questions_and_answers.csv\")\n",
    "question_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute our flow\n",
    "\n",
    "The below will invoke our flow and store the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_outputs = []\n",
    "for question in tqdm(question_set['question']):\n",
    "\n",
    "    response = bedrock_agent_rt.invoke_flow(\n",
    "        flowAliasIdentifier=flow_alias,\n",
    "        flowIdentifier=flow_id,\n",
    "        inputs=[\n",
    "            {\n",
    "                'content': {\n",
    "                    'document': question\n",
    "                },\n",
    "                'nodeName': 'UserInput',\n",
    "                'nodeOutputName': 'document'\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    flow_output = [response for response in iter(response['responseStream'])]\n",
    "\n",
    "    flow_outputs.append(flow_output[0]['flowOutputEvent']['content']['document'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute evaluation\n",
    "\n",
    "Now that we have our prompt flow responses, we can evaluate them using the Ragas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = []\n",
    "for context in tqdm(question_set['llm_contexts']):\n",
    "    eval(context)\n",
    "    context_list.append(eval(context))\n",
    "\n",
    "metrics = [\n",
    "          # context_precision,\n",
    "        # context_recall, # currently this metric might trigger timeout error raised by bedrock: ValueError: Error raised by bedrock service: Read timeout on endpoint URL: \"https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-v2/invoke\"\n",
    "        answer_similarity,\n",
    "        answer_correctness,\n",
    "        # answer_relevancy,\n",
    "        # faithfulness\n",
    "]\n",
    "\n",
    "column_map = {\n",
    "        \"question\": \"question\",\n",
    "        \"contexts\": \"llm_contexts\",\n",
    "        \"answer\": \"llm_answer\",\n",
    "        \"reference\": \"reference\",\n",
    "    }\n",
    "\n",
    "ragas_dataset = Dataset.from_dict(    {\n",
    "        \"question\":question_set['question'],\n",
    "        \"llm_answer\":flow_outputs,\n",
    "        \"reference\":question_set['gt_answer'],\n",
    "        \"llm_contexts\":context_list[:]\n",
    "    })\n",
    "\n",
    "# Evaluate\n",
    "eval_result = evaluate(ragas_dataset, \n",
    "                       metrics=metrics, \n",
    "                       column_map=column_map, \n",
    "                       llm=llm_for_evaluation,\n",
    "                        embeddings=bedrock_embeddings, raise_exceptions=False)\n",
    "eval_result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
