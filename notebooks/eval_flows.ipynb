{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our flow\n",
    "\n",
    "This notebook shows how we can take the Amazon Bedrock Knowledge Bases we created in `rag-router.ipynb` and put them in a structured flow using Amazon Bedrock Prompt Flows (https://aws.amazon.com/bedrock/prompt-flows/).\n",
    "\n",
    "This will allow us to have a versioned flow where we can specify all of the sequential components, as well as any conditions we want to model. \n",
    "\n",
    "We will start with a description of a RAG framework with additional modules (e.g., current date, web search, etc.) to generate a prompt flow as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "from langchain_aws.chat_models.bedrock import ChatBedrock\n",
    "from langchain_aws.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_aws.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    "    answer_relevancy,\n",
    "    faithfulness\n",
    "    )\n",
    "\n",
    "model_id_eval = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                                    config=bedrock_config)\n",
    "llm_for_evaluation = ChatBedrock(model_id= model_id_eval, client=bedrock_client)\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\",\n",
    "                                                    client=bedrock_client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "          context_precision,\n",
    "        context_recall, # currently this metric might trigger timeout error raised by bedrock: ValueError: Error raised by bedrock service: Read timeout on endpoint URL: \"https://bedrock-runtime.us-east-1.amazonaws.com/model/anthropic.claude-v2/invoke\"\n",
    "        answer_similarity,\n",
    "        answer_correctness,\n",
    "        answer_relevancy,\n",
    "        faithfulness\n",
    "]\n",
    "\n",
    "column_map = {\n",
    "        \"question\": \"question\",\n",
    "        \"contexts\": \"llm_contexts\",\n",
    "        \"answer\": \"llm_answer\",\n",
    "        \"ground_truths\": \"reference_answer\",\n",
    "    }\n",
    "\n",
    "result_df = pd.read_csv(\"10QA.csv\")\n",
    "\n",
    "# Evaluate\n",
    "eval_result = evaluate(Dataset.from_pandas(result_df), \n",
    "                       metrics=metrics, \n",
    "                       column_map=column_map, \n",
    "                       llm=llm_for_evaluation,\n",
    "                        embeddings=bedrock_embeddings, raise_exceptions=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
